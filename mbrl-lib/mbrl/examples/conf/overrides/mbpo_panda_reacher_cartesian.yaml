# @package _group_
env: "panda_reacher_cartesian_env"
term_fn: "no_termination"
reward_fn: "panda_reacher_cartesian"
uncontrolled_states: False
save_video: "True"
learned_rewards: True

action_range: [0, 1]

num_steps: 400000
epoch_length: 1000
num_elites: 5
patience: 1
model_lr: 0.0001
model_wd: 0.00002
model_batch_size: 256
validation_ratio: 0.2
freq_train_model: 250
effective_model_rollouts_per_step: 400
rollout_schedule: [1, 15, 1, 1]
num_sac_updates_per_step: 40
sac_updates_every_steps: 1
num_epochs_to_retain_sac_buffer: 1

sac_alpha_lr: 0.0003
sac_actor_lr: 0.0003
sac_actor_update_frequency: 4
sac_critic_lr: 0.00003
sac_critic_target_update_frequency: 4
sac_target_entropy: -3
sac_hidden_depth: 2

#network parametes
hidden_layer_size: 128
num_layers: 3

#checkpoints
load_model: False
load_agent: False
model_dir: "/home/akhil/PhD/RoL/Robotic-mbrl/mbrl-lib/exp/mbpo/default/panda_reacher_cartesian_env/2022.04.01/142346"
agent_dir: "/home/akhil/PhD/RoL/Robotic-mbrl/mbrl-lib/exp/mbpo/default/panda_reacher_cartesian_env/2022.04.01/142346"
